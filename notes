###### 26_05_17
# jenny happy with the output from the run through above on sample 45.
# going to run it on every sample now

1. update your nucleotide database. new files must be merged and converted into a blast database.

perl update_blastdb.pl nr
open up qiime in the terminal

go into the directory containing a folder for each sample.
each subfolder should only contain two files, the R1 file and the R2 file.
It assumed all your folders start wikth "Sample_01" or similar, as this will e used to name files later, The 1-9 below selects that region so change accoridngl.y
run this and check there is nothing other than R1 and R2 present:   (*Sample should allow it to search through each folder)
for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; cd $x ; ls | head -n 1 ; ls | sed -n 2p ; cd ../ ; done

Assuming all OK (only two files in each, the files are paired up correctly)

Assemble all the R1 and R2 files like this:

for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; echo "Assembling $output"; cd $x ; R1=$(ls | head -n 1) ; R2=$(ls | sed -n 2p) ; join_paired_ends.py -f "$R1" -r "$R2" -o "$output"_assembled.fastq ; cd ../ ; done

Check all the assembled file:
for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; cd "$x"/"$output"_assembled.fastq ; ls ; cd ../../ ; done

Remove the unjoined files (the  un1 and un2 files)

for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; cd "$x"/"$output"_assembled.fastq ; rm *un1* *un2* ; cd ../../ ; done

Perform Cutadapt
cutadapt Sample45_assembled.fasta -g CAACGATGAAGAACGCAGC -g CATCGATGAAGAACGTAGC  -g CAACGATGAAGAACGTAGC -g CATCGATGAAGAACGCAGC -a AGTTTCTTTTCCTCCGCTTA -a GGTTTCTTTTCCTCCGCTTA -n 2 -o 45_assembled_primers_removed --untrimmed-output /dev/null

Convert to fasta using fasta_fastq_convert.py:

for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; cd "$x"/"$output"_assembled.fastq ; ../../fastq_fasta_converter.py -i *_primers_removed.fastq -o "$x".fasta ; cd ../../ ; done


empty seqs removed withfasta_sanity_checker_and_converter.py

for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; echo "Converting $output"; cd "$x"/"$output"_assembled.fastq ; ../../fasta_sanity_checker_and_corrector.py -i *.fasta -o "$x"_checked.fasta ; cd ../../ ; done

run pick_otus.py

for x in `find Sample* -maxdepth 0 -type d` ; do output=$(echo $x | cut -c1-9) ; echo "Picking OTUs from sample $output"; cd "$x"/"$output"_assembled.fastq ; pick_open_reference_otus.py -i *_checked.fasta -r ../../utax_sequence_file.fasta -o ../otus -p ../../graeme_param_file.txt --suppress_align_and_tree ; cd ../../ ; done



BIOINFORMATICS METHODS:
Reads from the Illumina HiSeq were de-multiplexed using the Illumina barcoding
regions by the sequencing centre producing a pair of FastQ files for each
sample, for each barcoding region amplified. Pairs of files were assembled using
the QIIME (Caporaso et al. 2010) script 'join_paired_ends.py' using the default
settings. Read couplets which failed to be assembled were discarded. The program
CutAdapt (Marcel, 2011) was used to remove primer sequences (paper where primers
are from) from the reads and the fastq files converted to fasta.

The QIIME tool
'pick_open_reference_otus.py' was used with an ITS (internal transcribed spacer)
sequence database database derived from (generated by in-house Python script)
 the 'UTAX' barcode database published by Sickel and colleagues
(2015) passed as the reference database.
The option 'enable_rev_strand_match'
was set to 'True' and the sequences were clusted around 0.95 similarity.
The resulting biom tables were converted from binary format to text using
'biom convert' (McDonald et al. 2012).
A custom Python script was used to calculate relative abundance of OTUs and to
assign taxonomy information from the UTAX database to each OTU. Sequences which
had 100% similarity to at least 75% of the entry in the database were assigned
using Blastn (Camacho, 2008).
Where no sufficiently matching taxaonomy entry is found in the database the
OTU sequence is compared to the NCBI nucleotide database using Blastn. The top
Blastn result was assigned provided it was >95% similarity and >95% sequence
coverage. The taxonomy Genbank identifiers returned by Blastn were converted to
taxonomy identifiers using the tool 'gb_taxonomy_tools' (not sure how to ref
this right now as it is just a tool in the github of a guy from Temple University)
which allowed us to assign full taxonomy information to the GenBank sequence
assigned to the OTU. In keeping with the resolution of the 'UTAX' database and
the fact that we did not have access to full length ITS sequences from our own data
we assigned to genus level only.  





REFS

Camacho C et al (2008) BLAST+: architecture and applications." BMC Bioinformatics 10:421

Caporaso JG et al (2010)QIIME allows analysis of high-throughput community sequencing data. Nature Methods, 2010; doi:10.1038/nmeth.f.303

M Marcel (2011) Cutadapt Removes Adapter Sequences From High-Throughput Sequencing Reads. EMBnet.journal, [S.l.], v. 17, n. 1, p. pp. 10-12. ISSN 2226-6089. Available at: <http://journal.embnet.org/index.php/embnetjournal/article/view/200/479>. Date accessed: 05 Jun. 2017. doi:http://dx.doi.org/10.14806/ej.17.1.200.

McDonaly, D et al (2012) The Biological Observation Matrix (BIOM) format or: how I learned to stop worrying and love the ome-ome. GigaScience 2012, 1:7. doi:10.1186/2047-217X-1-7

Sickel et al. (2013) Increased efficiency in identifying mixed pollen samples by meta-barcoding with a duel indexing approach. BMC Ecol. 15:20. DOI 10.1186/s12898-015-0051-y.
